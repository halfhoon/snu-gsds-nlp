{"cells":[{"cell_type":"markdown","metadata":{"id":"lhs1disrZWXy"},"source":["# 2. Sentiment Analysis using Neural Network\n","\n","In class, we learned sequence representation and how language models are developed for different tasks. In this assignment, we will implement two neural network models for sentiment analysis task using IMDB dataset. Sentiment analysis in Natural Language Processing (NLP) is a task that involves classifying sentences or text into different categories based on the sentiment expressed. It aims to determine whether the sentiment of the text is positive, or negative. This analysis helps in understanding the overall opinion or emotion conveyed by the text.\n","\n","Please note that this assignment is built and tested under *Google Colaboratory*. If you work on a local machine, you need to handle version issue on your own. Please complete the given jupyter notebook file and submit it along with your answer to this latex file."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"fGurOjzMY1vv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800419024,"user_tz":-540,"elapsed":1949,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"ff570901-754e-40c4-eb39-4cc28dd64d1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"M-5EqJZlYseM"},"source":["## Data Preprocessing\n","\n","In this assignment, we will use TorchText package to deal with the data. There are a few ways to process the data, but this package makes this procedure much easier. Now we will go over the next steps with TorchText:\n","\n","- Preprocessing\n","- Split into train and test set\n","- Build dataset\n","- Building vocabulary\n","- Batching the data\n","\n","Once you load the data, there will be two columns, review comment and sentiment label (1 for positive and 0 for negative).\n","Out of 50000 sample data, we will use 30000 as our training set and rest of the data as our test set.\n","You can refer to [here](https://torchtext.readthedocs.io/en/latest/index.html) for more information on the TorchText."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qIG5GguwiXZK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800407325,"user_tz":-540,"elapsed":5641,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"ca101b1a-2e10-410f-fa9f-716002583784"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.32.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.4.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.26.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torchtext\n","Successfully installed torchtext-0.6.0\n"]}],"source":["!pip install torchtext==0.6.0"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Pil9y5s0PcOF","executionInfo":{"status":"ok","timestamp":1728800417077,"user_tz":-540,"elapsed":9754,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["import urllib.request\n","import pandas as pd\n","from torchtext import data, datasets\n","from torchtext.vocab import Vocab\n","from torchtext.data import TabularDataset\n","from torchtext.data import Iterator"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lBIS93RDWCWh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800421040,"user_tz":-540,"elapsed":2017,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"d02bb895-6492-458c-ef54-e5ac5feee424"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x7b81d017dcc0>)"]},"metadata":{},"execution_count":5}],"source":["# load data\n","urllib.request.urlretrieve(\n","    \"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\",\n","    filename=\"IMDb_Reviews.csv\",\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Vlt0g24XWDhG","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1728800425768,"user_tz":-540,"elapsed":4730,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"efd90613-8bfc-4109-b053-a01f8e5b6551"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              review  sentiment\n","0  My family and I normally do not watch local mo...          1\n","1  Believe it or not, this was at one time the wo...          0\n","2  After some internet surfing, I found the \"Home...          0\n","3  One of the most unheralded great works of anim...          1\n","4  It was the Sixties, and anyone with long hair ...          0"],"text/html":["\n","  <div id=\"df-843939eb-a235-4547-b415-1ea659fd3453\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>My family and I normally do not watch local mo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Believe it or not, this was at one time the wo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>After some internet surfing, I found the \"Home...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>One of the most unheralded great works of anim...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>It was the Sixties, and anyone with long hair ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-843939eb-a235-4547-b415-1ea659fd3453')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-843939eb-a235-4547-b415-1ea659fd3453 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-843939eb-a235-4547-b415-1ea659fd3453');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1fc59fa6-10a4-4afb-b2cb-2393659ff0f0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fc59fa6-10a4-4afb-b2cb-2393659ff0f0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1fc59fa6-10a4-4afb-b2cb-2393659ff0f0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"Perhaps you won't care for the social commentary, or the film makers point of view (I myself am mystified at the \\u00c2\\u0091insignificance' angle Kasdan seemed to promote \\u00c2\\u0096 when clearly, the actions taken in the movie promote CERTAIN significance. The ending confused me). However, there's absolutely no denying the manner in which the story is presented; the magnificent symbolism throughout; the threaded character arcs; visuals; dialogue \\u00c2\\u0096 is absolute masterwork. I've watched the movie dozens of times, and I still marvel at its perfection. There's not a moment, action, cut, or line that doesn't have everything to do with the theme. Realistic human performances from all the actors. Scene to scene it's woven fantastically.<br /><br />I have a pretty level sap-meter. The buzzer never went off during this film. If you're a thinker (rather than a casual viewer) \\u00c2\\u0096 this movie delivers. Exponentially. Absolutely mesmerizing. (Do you have to agree with the message to appreciate the display? Who cares if it made you warm and fuzzy or not, was it interesting?)<br /><br />Personally, the movie affected me \\u00c2\\u0096 significantly. In my top 5.<br /><br />Note: The front-page reviewer clearly speaks from a flawed African American perception. What he may have failed to recognize, is, there was a hand \\u00c2\\u0096 shake. Not a hand - out. The \\u00c2\\u0091spiritually dead white man', simply saw a man to respect, and admire. And he did something about it. The fact he was black had little, if anything, to do with it (color is simply used to draw the parallel. And the chasm. It's no accident the opening sequence shifts from black and white to color either). If you view the blacks in this movie as \\u00c2\\u0091token' \\u00c2\\u0096 you may want to reassess YOUR angst. You may be seeing only black and white yourself, eh. Just a thought.\",\n          \"Good Folks, I stumbled on this film on evening while I was grading papers. My academic specialty is Anglo-Saxon literature, and I can say that no one has ever done the genre the honor it deserves. The Icelandic \\\"Beowulf and Grendel\\\" is the least offensive I have seen, and I did pay $3.00 for my copy. This Sci-Fi version ranks with the Christopher Lambert version. Yuck.<br /><br />What didn't I like? CGI for one. Amazingly bad. More importantly is the faithfulness to the storyline, not to mention the stilted acting. I am used to both with all the versions I have seen.<br /><br />Delighted Regardless, Peter\",\n          \"\\\"Tipping The Velvet\\\" is one of the modern day television productions that prove that some television can be just as good or even better(as this is) than what you see at your local theater. <br /><br />If you want to read the plot, read this and if you want other details skip down to the next paragraph. This is the unforgettable portrait of an unconventional young girl named Nan who works as a naive oyster girl,until she discovers her repressed homosexuality when she falls in love with a successful woman named Kitty who dresses as a male for her stage profession. The young girl soon joins the act as another male impersonator and they are a major hit. Soon the both of them embark on a tender affair. Kitty eventually becomes enveloped in a marriage of convenience and ravages young Nan's heart. From then on, Nan works as male impersonated prostitute to men looking to have sex with boys, then she becomes the private sex slave to the evil and sadomasochistic Diana where Nan experiences severe emotional abuse. When that ends badly, Nan is on the streets again where she recalls a young woman named Florence; a good-hearted socialist who had the true potential of being a wonderful partner. That's where Nan will discover the power of socialism and learn how to get back to fame. <br /><br />The region 1 transfer is of exceptional picture quality, there is a very good scene selection, an eloquent photo gallery and a fun interview between novelist Sara Waters and the film's writer Andrew Davies. <br /><br />The sets, costumes, cinematography and music are gorgeous. The acting, writing and directing are extremely strong and filled with realism, class and originality. I loved the film and the novel. Section III in the film is much different in the film than in the novel, because section III in the novel is great written down, but isn't screen material. I will be brave and say that I love the films interpretation of it much more. <br /><br />This breathtaking historical ingeniously combines Drama, Comedy, Erotica and Romance to vibrant perfection in a way that is both deeply moving and spiritually uplifting. For every mature and open-minded adult who has ever felt the pleasures, pains and power of falling in love and living life to it's fullest. A revolutionary production; an absolute must-see!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["df = pd.read_csv(\"IMDb_Reviews.csv\", encoding=\"latin1\")\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"fwrEtY3YWGMS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800425768,"user_tz":-540,"elapsed":3,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"9b4ed6c9-05a1-4ce3-df5a-ed739130d5f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of sample data: 50000\n"]}],"source":["print(\"Total number of sample data: {}\".format(len(df)))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"XlWMZKeHWJls","executionInfo":{"status":"ok","timestamp":1728800432784,"user_tz":-540,"elapsed":7018,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["train_df = df[:30000]\n","test_df = df[30000:]\n","\n","train_df.to_csv(\"train_data.csv\", index=False)\n","test_df.to_csv(\"test_data.csv\", index=False)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"YW4JkUJtWKuW","executionInfo":{"status":"ok","timestamp":1728800432784,"user_tz":-540,"elapsed":2,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["# data preprocessing\n","TEXT = data.Field(\n","    sequential=True,\n","    use_vocab=True,\n","    tokenize=str.split,\n","    lower=True,\n","    batch_first=True,\n","    fix_length=100,\n",")\n","\n","LABEL = data.Field(sequential=False, use_vocab=False, batch_first=False, is_target=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"qE-s8tWdWRmH","executionInfo":{"status":"ok","timestamp":1728800443821,"user_tz":-540,"elapsed":11038,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["# build dataset\n","train_data, test_data = TabularDataset.splits(\n","    path=\".\",\n","    train=\"train_data.csv\",\n","    test=\"test_data.csv\",\n","    format=\"csv\",\n","    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n","    skip_header=True,\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"aT1Brmh8WTUV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800443821,"user_tz":-540,"elapsed":5,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"bbc9064f-4033-4fb4-fd5b-2bf1960dfbf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of training data : 30000\n","number of test data : 20000\n"]}],"source":["print(\"number of training data : {}\".format(len(train_data)))\n","print(\"number of test data : {}\".format(len(test_data)))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"tnwO8cnEWiDP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800443821,"user_tz":-540,"elapsed":5,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"4cff9afb-9aee-4819-ae0d-afd531849ffb"},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_items([('text', <torchtext.data.field.Field object at 0x7b81d017ff40>), ('label', <torchtext.data.field.Field object at 0x7b81d017fcd0>)])\n"]}],"source":["print(train_data.fields.items())"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"UDllSsureQ6v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800443821,"user_tz":-540,"elapsed":4,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"0d347693-e0b8-4f84-a5f1-17fe886edf45"},"outputs":[{"output_type":"stream","name":"stdout","text":["['my', 'family', 'and', 'i', 'normally', 'do', 'not', 'watch', 'local', 'movies', 'for', 'the', 'simple', 'reason', 'that', 'they', 'are', 'poorly', 'made,', 'they', 'lack', 'the', 'depth,', 'and', 'just', 'not', 'worth', 'our', 'time.<br', '/><br', '/>the', 'trailer', 'of', '\"nasaan', 'ka', 'man\"', 'caught', 'my', 'attention,', 'my', 'daughter', 'in', \"law's\", 'and', \"daughter's\", 'so', 'we', 'took', 'time', 'out', 'to', 'watch', 'it', 'this', 'afternoon.', 'the', 'movie', 'exceeded', 'our', 'expectations.', 'the', 'cinematography', 'was', 'very', 'good,', 'the', 'story', 'beautiful', 'and', 'the', 'acting', 'awesome.', 'jericho', 'rosales', 'was', 'really', 'very', 'good,', \"so's\", 'claudine', 'barretto.', 'the', 'fact', 'that', 'i', 'despised', 'diether', 'ocampo', 'proves', 'he', 'was', 'effective', 'at', 'his', 'role.', 'i', 'have', 'never', 'been', 'this', 'touched,', 'moved', 'and', 'affected', 'by', 'a', 'local', 'movie', 'before.', 'imagine', 'a', 'cynic', 'like', 'me', 'dabbing', 'my', 'eyes', 'at', 'the', 'end', 'of', 'the', 'movie?', 'congratulations', 'to', 'star', 'cinema!!', 'way', 'to', 'go,', 'jericho', 'and', 'claudine!!']\n","1\n"]}],"source":["print(train_data[0].text)\n","print(train_data[0].label)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"PCwqPZfzeYl7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800443821,"user_tz":-540,"elapsed":3,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"3f2e462c-0a1a-41cc-b1d3-aef743e5e85c"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': ['my', 'family', 'and', 'i', 'normally', 'do', 'not', 'watch', 'local', 'movies', 'for', 'the', 'simple', 'reason', 'that', 'they', 'are', 'poorly', 'made,', 'they', 'lack', 'the', 'depth,', 'and', 'just', 'not', 'worth', 'our', 'time.<br', '/><br', '/>the', 'trailer', 'of', '\"nasaan', 'ka', 'man\"', 'caught', 'my', 'attention,', 'my', 'daughter', 'in', \"law's\", 'and', \"daughter's\", 'so', 'we', 'took', 'time', 'out', 'to', 'watch', 'it', 'this', 'afternoon.', 'the', 'movie', 'exceeded', 'our', 'expectations.', 'the', 'cinematography', 'was', 'very', 'good,', 'the', 'story', 'beautiful', 'and', 'the', 'acting', 'awesome.', 'jericho', 'rosales', 'was', 'really', 'very', 'good,', \"so's\", 'claudine', 'barretto.', 'the', 'fact', 'that', 'i', 'despised', 'diether', 'ocampo', 'proves', 'he', 'was', 'effective', 'at', 'his', 'role.', 'i', 'have', 'never', 'been', 'this', 'touched,', 'moved', 'and', 'affected', 'by', 'a', 'local', 'movie', 'before.', 'imagine', 'a', 'cynic', 'like', 'me', 'dabbing', 'my', 'eyes', 'at', 'the', 'end', 'of', 'the', 'movie?', 'congratulations', 'to', 'star', 'cinema!!', 'way', 'to', 'go,', 'jericho', 'and', 'claudine!!'], 'label': '1'}\n"]}],"source":["print(vars(train_data[0]))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"7Wy90HN9Wj67","executionInfo":{"status":"ok","timestamp":1728800446819,"user_tz":-540,"elapsed":3000,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["# build vocabulary\n","TEXT.build_vocab(train_data, min_freq=10, max_size=10000)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"LsHXDKTEWvPO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800446819,"user_tz":-540,"elapsed":5,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"599244cc-219d-4c9c-c6d5-6232438fdedf"},"outputs":[{"output_type":"stream","name":"stdout","text":["size of the vocabulary : 10002\n"]}],"source":["print(\"size of the vocabulary : {}\".format(len(TEXT.vocab)))  # includes <unk> and <pad>"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"Fn0hJcSbWx6W","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1nq6LR_xsKM8PFh-C3x7FPwVS--zk2YDl"},"executionInfo":{"status":"ok","timestamp":1728803935890,"user_tz":-540,"elapsed":175,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"2c49d136-3515-4dce-efdc-460473766c1c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["print(TEXT.vocab.stoi)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"f9iXxEd7XS8Z","executionInfo":{"status":"ok","timestamp":1728800446819,"user_tz":-540,"elapsed":4,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["# build data loader and batching the data\n","batch_size = 64\n","train_loader = Iterator(dataset=train_data, batch_size=batch_size)\n","test_loader = Iterator(dataset=test_data, batch_size=batch_size)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"eYZiR0YvXVgf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800446819,"user_tz":-540,"elapsed":4,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"d2eeb7a2-4dc3-4a72-8d79-5f6f260f7c6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of mini-batches for training data : 469\n","number of mini-batches for test data : 313\n"]}],"source":["print(\"number of mini-batches for training data : {}\".format(len(train_loader)))\n","print(\"number of mini-batches for test data : {}\".format(len(test_loader)))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Bet56QmhXXYD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800446820,"user_tz":-540,"elapsed":4,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"ff230054-cf6c-4086-aeb9-50dc2e11401a"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torchtext.data.batch.Batch'>\n"]}],"source":["batch = next(iter(train_loader))\n","print(type(batch))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ZqkMXibKXaq3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800447134,"user_tz":-540,"elapsed":317,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"d88369a5-3073-4e39-c916-1997803094f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 265,   29,    2,  ...,  584,   37,   33],\n","        [   3,  773, 2391,  ...,   22,   49, 7061],\n","        [  80, 2224,   26,  ...,    2,  369,  151],\n","        ...,\n","        [  84,    5,  376,  ...,   17,    2, 1305],\n","        [   2,   20,   41,  ...,  936,   75, 9638],\n","        [ 338, 4634,    0,  ...,   33,  215,    0]])\n"]}],"source":["print(batch.text)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"EsNt6WuDXhHE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728800447134,"user_tz":-540,"elapsed":3,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"50f8ed24-7ca9-4450-bdec-d2e129efd16a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0])\n"]}],"source":["print(batch.label)"]},{"cell_type":"markdown","metadata":{"id":"odFUQcT1izne"},"source":["## Problem 2-1. Multilayer Perceptron (MLP) (30 pts)\n","\n","In this question, we are going to implement a simple Multilayer Perceptron (MLP) model to classify IMDB dataset. MLP is the classical type of neural network, and they are comprised of one or more layers of neurons. Data is fed to the input layer, there may be one or more hidden layers providing levels of abstraction, and predictions will be made on the output layer."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"zr1l9eXFmlv-","executionInfo":{"status":"ok","timestamp":1728800447134,"user_tz":-540,"elapsed":3,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"03HnknkuvFrE"},"source":["### Problem 2-1 (a) (10 pts)\n","\n","Implement a two-layer fully-connected neural network. Your model should contain an embedding layer to represent a word in a dense vector representation. Use ReLU for activation function."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"M2MgCMmKji1w","executionInfo":{"status":"ok","timestamp":1728801066546,"user_tz":-540,"elapsed":294,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["class Linear(nn.Module):\n","    def __init__(self, input_size, hidden_size, embed_dim, num_classes):\n","        super(Linear, self).__init__()\n","        #################### YOUR CODE (3 lines) #####################\n","        self.embedding = nn.Embedding(len(TEXT.vocab), embed_dim)\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","        ###############################################################\n","\n","    def forward(self, text):\n","        #################### YOUR CODE (3-5 lines) #####################\n","        # hint: you can use F.relu and F.softmax\n","        embedded = self.embedding(text).mean(dim=1)\n","        tmp = F.relu(self.fc1(embedded))\n","        preds = self.fc2(tmp)\n","        ###############################################################\n","        return preds"]},{"cell_type":"markdown","metadata":{"id":"rh1PiRmGxTtB"},"source":["### Problem 2-1 (b) (10 pts)\n","\n","Implement a function to check the accuracy of your model."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ssC7GxiJyPiw","executionInfo":{"status":"ok","timestamp":1728800447134,"user_tz":-540,"elapsed":2,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["def model_accuracy(output, target):\n","    #################### YOUR CODE (2-3 lines) #####################\n","    pred_output = torch.argmax(output, dim=1)\n","    accuracy = (pred_output == target).float().mean()\n","    ###############################################################\n","    return accuracy"]},{"cell_type":"markdown","metadata":{"id":"2aLakQnpyXS2"},"source":["### Problem 2-1 (c) (5 pts)\n","\n","Complete the code below to train the model"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"gGaA84zSlYFb","executionInfo":{"status":"ok","timestamp":1728801061133,"user_tz":-540,"elapsed":274,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","\n","    loss_ep = 0\n","    acc_ep = 0\n","\n","    for batch in iterator:\n","        optimizer.zero_grad()\n","\n","        #################### YOUR CODE (1-2 lines) #####################\n","        output = model(batch.text).squeeze()\n","        ###############################################################\n","        loss = criterion(output, batch.label.squeeze())\n","        acc = model_accuracy(output, batch.label)\n","\n","        loss.backward()\n","        optimizer.step()\n","        loss_ep += loss.item()\n","        acc_ep += acc.item()\n","    return loss_ep / len(iterator), acc_ep / len(iterator)"]},{"cell_type":"markdown","metadata":{"id":"VyyXGom71KMT"},"source":["### Problem 2-1 (d) (5 pts)\n","\n","Complete the code below to evaluate the model"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"kw2YtEgG0gXX","executionInfo":{"status":"ok","timestamp":1728801055388,"user_tz":-540,"elapsed":260,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","\n","    loss_ep = 0\n","    acc_ep = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch in iterator:\n","            #################### YOUR CODE (1-2 lines) #####################\n","            output = model(batch.text).squeeze()\n","            ###############################################################\n","            loss = criterion(output, batch.label)\n","            acc = model_accuracy(output, batch.label)\n","\n","            loss_ep += loss.item()\n","            acc_ep += acc.item()\n","\n","    return loss_ep / len(iterator), acc_ep / len(iterator)"]},{"cell_type":"markdown","metadata":{"id":"vL_aVpXd2ZVI"},"source":["Now let's see the model performance"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"N8QjG2I8xRgh","executionInfo":{"status":"ok","timestamp":1728801057780,"user_tz":-540,"elapsed":290,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["def train_the_model(epochs, model, train_loader, valid_loader, optimizer, criterion):\n","\n","    for epoch in range(epochs):\n","\n","        train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n","        valid_loss, valid_acc = evaluate(model, valid_loader, criterion)\n","\n","        print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%\")\n","        print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%\")\n","\n","    torch.save(model.state_dict(), \"saved_weights_linear.pt\")"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"JsTmY9Wxulu7","executionInfo":{"status":"ok","timestamp":1728800989671,"user_tz":-540,"elapsed":308,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["# hyperparameter\n","num_epochs = 10\n","lr = 1e-4\n","max_token_length = 100\n","hidden_size = 100\n","embed_dim = 100\n","seed = 1\n","num_classes = 2"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"yfLhdkTmmehD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728801147534,"user_tz":-540,"elapsed":78576,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"e80a31d6-9206-41b3-82b6-6734d4da8323"},"outputs":[{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.690 | Train Acc: 54.08%\n","\t Val. Loss: 0.683 |  Val. Acc: 60.15%\n","\tTrain Loss: 0.672 | Train Acc: 61.08%\n","\t Val. Loss: 0.655 |  Val. Acc: 64.17%\n","\tTrain Loss: 0.638 | Train Acc: 65.34%\n","\t Val. Loss: 0.614 |  Val. Acc: 68.20%\n","\tTrain Loss: 0.597 | Train Acc: 69.13%\n","\t Val. Loss: 0.576 |  Val. Acc: 70.80%\n","\tTrain Loss: 0.561 | Train Acc: 71.49%\n","\t Val. Loss: 0.548 |  Val. Acc: 72.46%\n","\tTrain Loss: 0.533 | Train Acc: 73.43%\n","\t Val. Loss: 0.527 |  Val. Acc: 73.75%\n","\tTrain Loss: 0.511 | Train Acc: 74.94%\n","\t Val. Loss: 0.511 |  Val. Acc: 74.78%\n","\tTrain Loss: 0.492 | Train Acc: 76.24%\n","\t Val. Loss: 0.498 |  Val. Acc: 75.57%\n","\tTrain Loss: 0.476 | Train Acc: 77.28%\n","\t Val. Loss: 0.488 |  Val. Acc: 76.13%\n","\tTrain Loss: 0.462 | Train Acc: 78.22%\n","\t Val. Loss: 0.478 |  Val. Acc: 76.65%\n"]}],"source":["loss_function = nn.CrossEntropyLoss()\n","linear_model = Linear(max_token_length, hidden_size, embed_dim, num_classes)\n","optimizer = torch.optim.Adam(linear_model.parameters(), lr=lr)\n","\n","train_the_model(\n","    num_epochs, linear_model, train_loader, test_loader, optimizer, loss_function\n",")"]},{"cell_type":"markdown","metadata":{"id":"ZccIlM7P4o4O"},"source":["## Problem 2-2. Convolutional Neural Network (CNN) (20 pts)\n","\n","Next, we will perform sentimental analysis on the same dataset with Convolutional Neural Network (CNN). In a CNN, text is organised into a matrix, with each row representing a word embedding. The CNN’s convolutional layer scans the text like it would an image, breaks it down into features, and judges whether each feature matches the relevant label or not.\n","You can refer to [here](https://emnlp2014.org/papers/pdf/EMNLP2014181.pdf) for the use of CNN on text classification.\n"]},{"cell_type":"markdown","metadata":{"id":"3dZiilj0ZsyU"},"source":["### Problem 2-2 (a) (15 pts)\n","\n","Complete the code below for CNN. Again, your model will require an embedding layer to represent into dense vector. After getting embeddings, we will feed the tensors through the convolutional layer, applying the ReLu activation function following the convlutional layers. Then the tensors will be passed through pooling layers. Lastly, apply dropout to the concatenated filter outputs and subsequently pass them through a linear layer to *generate* our predictions."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"FDDXPBzGLjLX","executionInfo":{"status":"ok","timestamp":1728801269512,"user_tz":-540,"elapsed":290,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(\n","        self, input_dim, embed_dim, n_filters, filter_sizes, num_classes, dropout_rate\n","    ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(input_dim, embed_dim)\n","        # convolutions with different size of filters\n","        self.convs = nn.ModuleList(\n","            [\n","                nn.Conv2d(\n","                    in_channels=1,\n","                    out_channels=n_filters,\n","                    kernel_size=(filter_size, embed_dim),\n","                )\n","                for filter_size in filter_sizes\n","            ]\n","        )\n","\n","        self.fc = nn.Linear(len(filter_sizes) * n_filters, num_classes)\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, text):\n","        # text = [batch_size, sen_len]\n","\n","        embedded = self.embedding(text)\n","        # embedded = [batch_size, sen_len, embed_dim]\n","\n","        embedded = embedded.unsqueeze(1)\n","        # embedded = [batch_size, 1, sen_len, embed_dim]\n","\n","        #################### YOUR CODE (4 lines) #####################\n","        # hint: you can use F.relu, F.max_pool1d, and torch.cat\n","\n","        # After getting embeddings, we will feed the tensors through the convolutional layer, applying the ReLu activation function following the convlutional layers.\n","        # output size of the n-convolutional layer = [batch_size, n_filters, sen_len - filter_sizes[n] + 1]\n","        conv_out = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n","\n","\n","        # Then the tensors will be passed through pooling layers.\n","        # output size of the n-pooling layer = [batch_size, n_filters]\n","        pool_out = [F.max_pool1d(out, out.shape[2]).squeeze(2) for out in conv_out]\n","        pool_out = torch.cat(pool_out, dim=1)\n","\n","\n","        # Lastly, apply dropout to the concatenated filter outputs and subsequently pass them through a linear layer to generate our predictions.\n","        # output size of the dropout = [batch size, n_filters * len(filter_sizes)]\n","        drop = self.dropout(pool_out)\n","        output= self.fc(drop)\n","        ###############################################################\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"W6YgprZeeyi_"},"source":["Now let's see the model performance.\n","\n","We will use the same function that we used in MLP model for model training and evaluation.\n","It will take about 30 minutes to run 5 epochs"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"M3fmVYj1LjFj","executionInfo":{"status":"ok","timestamp":1728801271413,"user_tz":-540,"elapsed":290,"user":{"displayName":"최재훈","userId":"05422267510630499720"}}},"outputs":[],"source":["# hyperparameter\n","num_epochs = 5\n","lr = 1e-4\n","input_dim = len(TEXT.vocab)\n","embed_dim = 300\n","num_filters = 100\n","filter_sizes = [3, 5, 7]\n","dropout_rate = 0.25\n","num_classes = 2"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WujCcBwLjBo","executionInfo":{"status":"ok","timestamp":1728803933555,"user_tz":-540,"elapsed":2661361,"user":{"displayName":"최재훈","userId":"05422267510630499720"}},"outputId":"9ed4153c-6c41-4d4d-c5ba-850125c9d5bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.671 | Train Acc: 59.68%\n","\t Val. Loss: 0.563 |  Val. Acc: 71.97%\n","\tTrain Loss: 0.504 | Train Acc: 77.34%\n","\t Val. Loss: 0.513 |  Val. Acc: 74.90%\n","\tTrain Loss: 0.420 | Train Acc: 83.32%\n","\t Val. Loss: 0.487 |  Val. Acc: 76.46%\n","\tTrain Loss: 0.340 | Train Acc: 88.64%\n","\t Val. Loss: 0.463 |  Val. Acc: 77.78%\n","\tTrain Loss: 0.266 | Train Acc: 92.60%\n","\t Val. Loss: 0.445 |  Val. Acc: 78.89%\n"]}],"source":["cnn_model = CNN(\n","    input_dim, embed_dim, num_filters, filter_sizes, num_classes, dropout_rate\n",")\n","\n","\n","optimizer = torch.optim.Adam(cnn_model.parameters(), lr=lr)\n","\n","train_the_model(\n","    num_epochs, cnn_model, train_loader, test_loader, optimizer, loss_function\n",")"]},{"cell_type":"markdown","metadata":{"id":"wJJaN8CTwnzK"},"source":["### Problem 2-2 (b) (5 pts)\n","\n","Compare the linear model (problem 1) and CNN (problem 2), and discuss their advantages and limitations."]},{"cell_type":"markdown","metadata":{"id":"WYXPjGJtwsIT"},"source":["The linear model (problem 1) obtains results quickly with fewer parameters but has lower accuracy. In contrast, the CNN (problem 2) uses many hyperparameters to achieve high accuracy even with fewer epochs, but it is slower and can suffer from overfitting. From the code execution results, we can see that the CNN (problem 2) converges quickly in fewer epochs. However, since it trains significantly more parameters than the linear model, it takes a very long time to train."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"snu-nlp-MhIcQQWm-py3.11","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}